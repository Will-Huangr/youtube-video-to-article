#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YouTubeè§†é¢‘è½¬å›¾æ–‡æ–‡ç« ç”Ÿæˆå™¨ - ä¿®å¤ç‰ˆæœ¬
"""

import os
import json
import logging
from flask import Flask, render_template, request, jsonify
import requests
from youtube_transcript_api import YouTubeTranscriptApi
import re
import subprocess
import tempfile
import glob
import config # å¯¼å…¥é…ç½®æ–‡ä»¶

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆ›å»ºFlaskåº”ç”¨
app = Flask(__name__)

# APIé…ç½®
DIFY_API_URL = config.DIFY_API_URL
DIFY_API_KEY = config.DIFY_API_KEY
IMAGE_API_ACCESS_KEY = config.IMAGE_API_ACCESS_KEY
IMAGE_API_SECRET_KEY = config.IMAGE_API_SECRET_KEY

SUPPORTED_LANGUAGES = {
    'en': 'English',
    'zh-Hans': 'ä¸­æ–‡(ç®€ä½“)',
    'zh-Hant': 'ä¸­æ–‡(ç¹ä½“)',
    'ja': 'æ—¥æœ¬èª',
    'ko': 'í•œêµ­ì–´',
    'es': 'EspaÃ±ol',
    'fr': 'FranÃ§ais',
    'de': 'Deutsch',
    'ru': 'Ğ ÑƒÑÑĞºĞ¸Ğ¹',
    'ar': 'Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©'
}

def extract_text_from_subtitle(content, file_type='auto'):
    """
    ä»å­—å¹•æ–‡ä»¶å†…å®¹ä¸­æå–çº¯æ–‡æœ¬
    æ”¯æŒSRTå’ŒVTTæ ¼å¼
    """
    try:
        lines = content.split('\n')
        text_segments = []
        
        if file_type == 'auto':
            # è‡ªåŠ¨æ£€æµ‹æ ¼å¼
            if content.startswith('WEBVTT') or 'WEBVTT' in content[:100]:
                file_type = 'vtt'
            else:
                file_type = 'srt'
        
        if file_type == 'vtt':
            # å¤„ç†WebVTTæ ¼å¼
            for line in lines:
                line = line.strip()
                
                # è·³è¿‡WebVTTå¤´éƒ¨ã€æ—¶é—´æˆ³è¡Œã€ç©ºè¡Œã€ä½ç½®ä¿¡æ¯
                if (not line or 
                    line.startswith('WEBVTT') or 
                    line.startswith('Kind:') or 
                    line.startswith('Language:') or 
                    '-->' in line or
                    'align:start position:' in line or
                    line.startswith('NOTE')):
                    continue
                
                # å»é™¤HTMLæ ‡ç­¾å’Œæ—¶é—´æˆ³æ ‡è®°
                clean_line = re.sub(r'<[^>]+>', '', line)
                clean_line = re.sub(r'<[0-9:.]+>', '', clean_line)
                clean_line = re.sub(r'\s+', ' ', clean_line).strip()
                
                if clean_line:
                    text_segments.append(clean_line)
        
        else:  # SRTæ ¼å¼
            # å¤„ç†SRTæ ¼å¼
            i = 0
            while i < len(lines):
                line = lines[i].strip()
                
                # è·³è¿‡ç©ºè¡Œ
                if not line:
                    i += 1
                    continue
                
                # è·³è¿‡åºå·è¡Œï¼ˆçº¯æ•°å­—ï¼‰
                if line.isdigit():
                    i += 1
                    continue
                
                # è·³è¿‡æ—¶é—´æˆ³è¡Œ
                if '-->' in line:
                    i += 1
                    continue
                
                # å¤„ç†æ–‡æœ¬è¡Œ
                if line and not line.isdigit() and '-->' not in line:
                    # å»é™¤HTMLæ ‡ç­¾
                    clean_line = re.sub(r'<[^>]+>', '', line)
                    clean_line = re.sub(r'\s+', ' ', clean_line).strip()
                    
                    if clean_line:
                        text_segments.append(clean_line)
                
                i += 1
        
        # åˆå¹¶æ‰€æœ‰æ–‡æœ¬
        full_text = ' '.join(text_segments)
        
        # å»é‡å¤„ç† - ç§»é™¤é‡å¤çš„å¥å­ç‰‡æ®µ
        words = full_text.split()
        unique_words = []
        seen_phrases = set()
        
        # æ¯5ä¸ªè¯ä½œä¸ºä¸€ä¸ªçŸ­è¯­è¿›è¡Œå»é‡
        for i in range(len(words)):
            word = words[i]
            # è·å–å½“å‰è¯åŠå…¶åé¢4ä¸ªè¯ä½œä¸ºçŸ­è¯­
            if i + 4 < len(words):
                phrase = ' '.join(words[i:i+5])
                if phrase not in seen_phrases:
                    unique_words.append(word)
                    seen_phrases.add(phrase)
            else:
                unique_words.append(word)
        
        # é‡æ–°ç»„åˆæ–‡æœ¬
        clean_text = ' '.join(unique_words)
        
        logger.info(f"æ–‡æœ¬æå–å®Œæˆ: æ ¼å¼={file_type}, åŸå§‹é•¿åº¦={len(full_text)}, å»é‡åé•¿åº¦={len(clean_text)}")
        
        return clean_text
        
    except Exception as e:
        logger.error(f"æ–‡æœ¬æå–å¤±è´¥: {e}")
        raise

def extract_youtube_subtitles_ytdlp(video_url, language='en'):
    """ä½¿ç”¨yt-dlpæå–YouTubeå­—å¹•çš„å¤‡é€‰æ–¹æ¡ˆ"""
    try:
        # æå–è§†é¢‘ID
        video_id_match = re.search(r'(?:v=|/)([0-9A-Za-z_-]{11})', video_url)
        if not video_id_match:
            raise Exception("æ— æ•ˆçš„YouTubeé“¾æ¥")
        
        video_id = video_id_match.group(1)
        logger.info(f"ä½¿ç”¨yt-dlpæå–è§†é¢‘ID: {video_id}")
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        with tempfile.TemporaryDirectory() as temp_dir:
            # æ„å»ºyt-dlpå‘½ä»¤ - åªä¸‹è½½å­—å¹•
            cmd = [
                'yt-dlp',
                '--write-subs',  # ä¸‹è½½å­—å¹•
                '--write-auto-subs',  # ä¸‹è½½è‡ªåŠ¨ç”Ÿæˆçš„å­—å¹•
                '--sub-langs', f'{language},en,en-US',  # å­—å¹•è¯­è¨€ä¼˜å…ˆçº§
                '--sub-format', 'vtt',  # å­—å¹•æ ¼å¼
                '--skip-download',  # ä¸ä¸‹è½½è§†é¢‘
                '--output', f'{temp_dir}/%(title)s.%(ext)s',
                f'https://www.youtube.com/watch?v={video_id}'
            ]
            
            logger.info("yt-dlpå‘½ä»¤: " + ' '.join(cmd))
            
            # æ‰§è¡Œå‘½ä»¤
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            
            if result.returncode != 0:
                logger.error(f"yt-dlpæ‰§è¡Œå¤±è´¥: {result.stderr}")
                raise Exception(f"yt-dlpå­—å¹•æå–å¤±è´¥: {result.stderr}")
            
            # æŸ¥æ‰¾å­—å¹•æ–‡ä»¶
            subtitle_files = glob.glob(f'{temp_dir}/*.vtt')
            
            if not subtitle_files:
                raise Exception("æœªæ‰¾åˆ°å­—å¹•æ–‡ä»¶")
            
            # è¯»å–ç¬¬ä¸€ä¸ªå­—å¹•æ–‡ä»¶
            subtitle_file = subtitle_files[0]
            logger.info(f"æ‰¾åˆ°å­—å¹•æ–‡ä»¶: {subtitle_file}")
            
            with open(subtitle_file, 'r', encoding='utf-8') as f:
                subtitle_content = f.read()
            
            # ä½¿ç”¨é€šç”¨å‡½æ•°æå–æ–‡æœ¬
            clean_text = extract_text_from_subtitle(subtitle_content, 'vtt')
            
            logger.info(f"yt-dlpå­—å¹•æå–æˆåŠŸï¼Œé•¿åº¦: {len(clean_text)} å­—ç¬¦")
            return clean_text
            
    except subprocess.TimeoutExpired:
        logger.error("yt-dlpæ‰§è¡Œè¶…æ—¶")
        raise Exception("yt-dlpæ‰§è¡Œè¶…æ—¶")
    except Exception as e:
        logger.error(f"yt-dlpå­—å¹•æå–å¤±è´¥: {e}")
        raise

def extract_youtube_subtitles(video_url, language='en'):
    """æå–YouTubeå­—å¹•å¹¶æœ¬åœ°å¤„ç†ä¸ºçº¯æ–‡æœ¬ - å¸¦å¤‡é€‰æ–¹æ¡ˆ"""
    try:
        # é¦–å…ˆå°è¯•ä½¿ç”¨youtube_transcript_api
        logger.info("å°è¯•ä½¿ç”¨youtube_transcript_apiæå–å­—å¹•...")
        return extract_youtube_subtitles_original(video_url, language)
        
    except Exception as api_error:
        logger.warning(f"youtube_transcript_apiå¤±è´¥: {api_error}")
        logger.info("åˆ‡æ¢åˆ°yt-dlpå¤‡é€‰æ–¹æ¡ˆ...")
        
        try:
            return extract_youtube_subtitles_ytdlp(video_url, language)
        except Exception as ytdlp_error:
            logger.error(f"yt-dlpä¹Ÿå¤±è´¥äº†: {ytdlp_error}")
            raise Exception(f"æ‰€æœ‰å­—å¹•æå–æ–¹æ³•éƒ½å¤±è´¥äº†ã€‚youtube_transcript_api: {str(api_error)[:100]}..., yt-dlp: {str(ytdlp_error)[:100]}...")

def extract_youtube_subtitles_original(video_url, language='en'):
    """æå–YouTubeå­—å¹•å¹¶æœ¬åœ°å¤„ç†ä¸ºçº¯æ–‡æœ¬"""
    try:
        # æå–è§†é¢‘ID
        video_id_match = re.search(r'(?:v=|/)([0-9A-Za-z_-]{11})', video_url)
        if not video_id_match:
            raise Exception("æ— æ•ˆçš„YouTubeé“¾æ¥")
        
        video_id = video_id_match.group(1)
        logger.info(f"æå–è§†é¢‘ID: {video_id}")
        
        # è·å–å­—å¹•åŸå§‹æ•°æ®
        transcript_data = YouTubeTranscriptApi.get_transcript(video_id, languages=[language, 'en', 'zh', 'auto'])
        logger.info(f"æˆåŠŸè·å–å­—å¹•ï¼Œå…±{len(transcript_data)}æ¡")
        
        # å°†transcript_dataè½¬æ¢ä¸ºSRTæ ¼å¼å­—ç¬¦ä¸²
        srt_content = ""
        for i, entry in enumerate(transcript_data, 1):
            start_time = entry['start']
            duration = entry['duration']
            end_time = start_time + duration
            text = entry['text'].replace('\n', ' ')
            
            def format_srt_time(seconds):
                hours = int(seconds // 3600)
                minutes = int((seconds % 3600) // 60)
                secs = int(seconds % 60)
                millis = int((seconds % 1) * 1000)
                return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"
            
            start_formatted = format_srt_time(start_time)
            end_formatted = format_srt_time(end_time)
            
            srt_content += f"{i}\n{start_formatted} --> {end_formatted}\n{text}\n\n"
        
        # ä½¿ç”¨é€šç”¨å‡½æ•°æå–æ–‡æœ¬
        clean_text = extract_text_from_subtitle(srt_content, 'srt')
        
        return clean_text
        
    except Exception as e:
        logger.error(f"å­—å¹•æå–å¤±è´¥: {e}")
        raise

def call_dify_workflow(subtitle_text, language, picture_style):
    """è°ƒç”¨Difyå·¥ä½œæµ"""
    try:
        # é™åˆ¶æ–‡æœ¬é•¿åº¦ï¼Œé¿å…Difyè¶…æ—¶
        if len(subtitle_text) > 5000:
            subtitle_text = subtitle_text[:5000]
            logger.info(f"æ–‡æœ¬è¿‡é•¿ï¼Œæˆªå–å‰5000å­—ç¬¦")
        
        dify_url = f"{DIFY_API_URL}/workflows/run"
        headers = {
            'Authorization': f'Bearer {DIFY_API_KEY}',
            'Content-Type': 'application/json'
        }
        
        payload = {
            'inputs': {
                'text': subtitle_text,
                'language': language,
                'picturestyle': picture_style or "",
                'secret_key': IMAGE_API_SECRET_KEY,
                'access_key': IMAGE_API_ACCESS_KEY
            },
            'response_mode': 'streaming',  # ä½¿ç”¨streamingæ¨¡å¼é¿å…è¶…æ—¶
            'user': f'user-{hash(subtitle_text) % 100000000}'
        }
        
        logger.info("è°ƒç”¨Difyå·¥ä½œæµ...")
        logger.info(f"å­—å¹•é•¿åº¦: {len(subtitle_text)} å­—ç¬¦")
        logger.info(f"å‚æ•°: language={language}, picturestyle={picture_style}")
        
        # ä½¿ç”¨streamingæ¨¡å¼ï¼Œé¿å…CloudFlare 60ç§’è¶…æ—¶
        try:
            logger.info("Difyè°ƒç”¨å¼€å§‹ï¼ˆstreamingæ¨¡å¼ï¼‰ï¼Œé¢„è®¡éœ€è¦1-2åˆ†é’Ÿ...")
            
            response = requests.post(dify_url, json=payload, headers=headers, timeout=300, stream=True)
            
            logger.info(f"å“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                # å¤„ç†streamingå“åº”
                content_parts = []
                title = 'AIç”Ÿæˆæ–‡ç« '
                images = []
                final_outputs = {}
                
                for line in response.iter_lines():
                    if line:
                        try:
                            line_str = line.decode('utf-8')
                            if line_str.startswith('data: '):
                                data_str = line_str[6:]  # å»æ‰ "data: " å‰ç¼€
                                if data_str.strip() == '[DONE]':
                                    break
                                
                                data = json.loads(data_str)
                                event = data.get('event', '')
                                
                                if event == 'workflow_finished':
                                    # å·¥ä½œæµå®Œæˆ
                                    outputs = data.get('data', {}).get('outputs', {})
                                    final_outputs = outputs
                                    title = outputs.get('title', 'AIç”Ÿæˆæ–‡ç« ')
                                    content = outputs.get('content', outputs.get('article', outputs.get('text', '')))
                                    images = outputs.get('images', [])
                                    
                                    # å¦‚æœimagesæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æ
                                    if isinstance(images, str):
                                        try:
                                            images = json.loads(images)
                                        except:
                                            images = []
                                    
                                    logger.info("âœ… Difyå·¥ä½œæµå®Œæˆï¼")
                                    break
                                    
                                elif event == 'node_finished':
                                    # èŠ‚ç‚¹å®Œæˆ
                                    node_data = data.get('data', {})
                                    logger.info(f"èŠ‚ç‚¹å®Œæˆ: {node_data.get('title', 'unknown')}")
                                    
                                elif event == 'text_chunk':
                                    # æ–‡æœ¬å—
                                    chunk = data.get('data', {}).get('text', '')
                                    content_parts.append(chunk)
                                    
                        except json.JSONDecodeError:
                            continue
                        except Exception as e:
                            logger.warning(f"å¤„ç†streamingæ•°æ®å‡ºé”™: {e}")
                            continue
                
                # å¦‚æœæ²¡æœ‰ä»workflow_finishedè·å–åˆ°å†…å®¹ï¼Œä½¿ç”¨ç´¯ç§¯çš„å†…å®¹
                if not final_outputs and content_parts:
                    content = ''.join(content_parts)
                elif final_outputs:
                    content = final_outputs.get('content', final_outputs.get('article', final_outputs.get('text', '')))
                else:
                    content = ''.join(content_parts) if content_parts else 'ç”Ÿæˆå¤±è´¥'
                
                return {
                    'title': title,
                    'content': content,
                    'images': images if isinstance(images, list) else [],
                    'dify_raw': final_outputs
                }
            else:
                logger.error(f"Dify APIé”™è¯¯: {response.status_code} - {response.text[:200]}")
                raise Exception(f"Dify APIè¿”å›é”™è¯¯: {response.status_code}")
                
        except requests.exceptions.Timeout:
            logger.error("Difyè°ƒç”¨è¶…æ—¶ï¼ˆ300ç§’ï¼‰")
            raise Exception("Dify APIè°ƒç”¨è¶…æ—¶ - å·¥ä½œæµæ‰§è¡Œæ—¶é—´è¿‡é•¿")
        
    except Exception as e:
        logger.error(f"Difyè°ƒç”¨å¤±è´¥: {e}")
        raise

def clean_generated_content(content):
    """æ¸…ç†ç”Ÿæˆå†…å®¹ä¸­çš„å¤šä½™ç©ºè¡Œå’Œé”™è¯¯ä¿¡æ¯"""
    if not content:
        return content
    
    # ç§»é™¤å›¾ç‰‡ç›¸å…³çš„é”™è¯¯ä¿¡æ¯
    lines = content.split('\n')
    cleaned_lines = []
    
    skip_image_error = False
    for line in lines:
        # æ£€æµ‹å¹¶è·³è¿‡å›¾ç‰‡ç›¸å…³çš„é”™è¯¯ä¿¡æ¯
        if 'ç”±äºæä¾›çš„å›¾ç‰‡åˆ—è¡¨ä¸­å›¾ç‰‡URLä¸ºç©º' in line or '401ï¼šæœªæˆæƒ' in line:
            skip_image_error = True
            continue
        
        if skip_image_error and ('å› æ­¤ï¼Œæˆ‘å°†ç›´æ¥è¾“å‡ºæ–‡ç« å†…å®¹' in line or 'ä»¥ä¸‹æ˜¯å®Œæ•´çš„æ–‡ç« å†…å®¹' in line):
            skip_image_error = False
            continue
            
        # è·³è¿‡è¿ç»­çš„ç©ºè¡Œï¼ˆè¶…è¿‡2ä¸ªï¼‰
        if line.strip() == '':
            # å¦‚æœå‰é¢å·²ç»æœ‰ç©ºè¡Œäº†ï¼Œå°±ä¸å†æ·»åŠ 
            if cleaned_lines and cleaned_lines[-1].strip() == '':
                continue
        
        cleaned_lines.append(line)
    
    # ç§»é™¤æœ«å°¾çš„è¿ç»­ç©ºè¡Œ
    while cleaned_lines and cleaned_lines[-1].strip() == '':
        cleaned_lines.pop()
    
    # ç§»é™¤å¼€å¤´çš„åˆ†éš”çº¿
    while cleaned_lines and cleaned_lines[0].strip() in ['---', '']:
        cleaned_lines.pop(0)
    
    return '\n'.join(cleaned_lines).strip()

@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('index.html', languages=SUPPORTED_LANGUAGES)

@app.route('/api/health')
def health_check():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        'status': 'healthy',
        'message': 'YouTubeè§†é¢‘è½¬å›¾æ–‡æ–‡ç« ç”Ÿæˆå™¨è¿è¡Œæ­£å¸¸',
        'config_valid': True
    })

@app.route('/api/process-video', methods=['POST'])
def process_video():
    """å¤„ç†è§†é¢‘ï¼Œç”Ÿæˆå›¾æ–‡æ–‡ç« """
    try:
        data = request.get_json()
        if not data:
            return jsonify({'error': 'è¯·æä¾›JSONæ•°æ®'}), 400
        
        video_url = data.get('video_url', '')
        language = data.get('language', 'en')
        picture_style = data.get('picture_style', '')
        
        if not video_url:
            return jsonify({'error': 'è¯·æä¾›è§†é¢‘URL'}), 400
        
        logger.info(f"å¤„ç†è§†é¢‘: {video_url}")
        
        # 1. æå–å­—å¹•
        try:
            subtitle_text = extract_youtube_subtitles(video_url, language)
            logger.info(f"å­—å¹•æå–æˆåŠŸï¼Œé•¿åº¦: {len(subtitle_text)} å­—ç¬¦")
        except Exception as e:
            return jsonify({'error': f'å­—å¹•æå–å¤±è´¥: {str(e)}'}), 400
        
        # 2. è°ƒç”¨Dify
        try:
            dify_result = call_dify_workflow(subtitle_text, language, picture_style)
            logger.info("Difyè°ƒç”¨æˆåŠŸ")
            
            # æ¸…ç†ç”Ÿæˆçš„å†…å®¹
            cleaned_content = clean_generated_content(dify_result['content'])
            
            result = {
                'success': True,
                'message': 'è§†é¢‘å¤„ç†å®Œæˆ (ä½¿ç”¨Dify AIç”Ÿæˆ)',
                'data': {
                    'title': dify_result['title'],
                    'content': cleaned_content,
                    'images': dify_result['images'],
                    'video_info': {
                        'url': video_url,
                        'language': language,
                        'picture_style': picture_style,
                        'duration': 'å¾…æå–'
                    },
                    'dify_raw': dify_result['dify_raw']
                }
            }
            
            return jsonify(result)
            
        except Exception as e:
            logger.warning(f"Difyè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ: {e}")
            
            # å¤‡é€‰æ–¹æ¡ˆï¼šåŸºäºå­—å¹•ç”Ÿæˆç®€å•æ–‡ç« 
            lines = subtitle_text.split('\n')
            text_lines = [line for line in lines if line and not line.startswith('WEBVTT') and not line.startswith('Kind:') and not line.startswith('Language:') and '-->' not in line]
            
            content = ' '.join(text_lines[:50])  # å–å‰50è¡Œå­—å¹•
            
            result = {
                'success': True,
                'message': 'è§†é¢‘å¤„ç†å®Œæˆ (Dify APIä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€å¤„ç†)',
                'data': {
                    'title': 'åŸºäºè§†é¢‘å†…å®¹çš„æ–‡ç« ',
                    'content': f"# è§†é¢‘å†…å®¹æ‘˜è¦\n\n{content}",
                    'images': [
                        {
                            'url': 'https://via.placeholder.com/400x300/667eea/ffffff?text=Video+Content',
                            'description': 'è§†é¢‘å†…å®¹é…å›¾',
                            'style': picture_style or 'professional'
                        }
                    ],
                    'video_info': {
                        'url': video_url,
                        'language': language,
                        'picture_style': picture_style,
                        'duration': 'å¾…æå–'
                    }
                }
            }
            
            return jsonify(result)
        
    except Exception as e:
        logger.error(f"å¤„ç†å¤±è´¥: {str(e)}")
        return jsonify({'error': f'å¤„ç†å¤±è´¥: {str(e)}'}), 500

@app.route('/api/demo', methods=['POST'])
def demo_process():
    """Demoæ¥å£ï¼Œç›´æ¥è°ƒç”¨Difyå·¥ä½œæµéªŒè¯æµç¨‹å¯è¡Œæ€§"""
    try:
        data = request.get_json()
        language = data.get('language', 'en')
        picture_style = data.get('picture_style', 'modern professional style')
        
        logging.info(f"Demoè¯·æ±‚ - è¯­è¨€: {language}, å›¾ç‰‡é£æ ¼: {picture_style}")
        
        # è¯»å–æµ‹è¯•æ–‡æ¡£
        try:
            with open('test_document.txt', 'r', encoding='utf-8') as f:
                test_text = f.read().strip()
        except FileNotFoundError:
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤æ–‡æœ¬
            test_text = '''Artificial Intelligence is revolutionizing the way we work and live. Machine learning algorithms can analyze vast amounts of data to identify patterns and make predictions with remarkable accuracy.

Deep learning neural networks mimic the human brain's structure, enabling computers to recognize images, understand natural language, and even generate creative content. Companies across industries are implementing AI solutions to automate processes, improve decision-making, and enhance customer experiences.

The future of AI holds immense potential for breakthroughs in healthcare, education, transportation, and scientific research. As these technologies continue to evolve, they will likely reshape our society in unprecedented ways.

However, the development of AI also raises important questions about ethics, privacy, and the future of human employment. It's crucial that we approach this technological advancement thoughtfully and responsibly.'''
        
        logging.info(f"ä½¿ç”¨æµ‹è¯•æ–‡æ¡£é•¿åº¦: {len(test_text)} å­—ç¬¦")
        
        # ç›´æ¥è°ƒç”¨Difyå·¥ä½œæµ
        try:
            logging.info("ğŸš€ å¼€å§‹è°ƒç”¨çœŸå®Difyå·¥ä½œæµ...")
            dify_result = call_dify_workflow(test_text, language, picture_style)
            logging.info("âœ… Difyå·¥ä½œæµè°ƒç”¨æˆåŠŸ")
            
            # æ¸…ç†ç”Ÿæˆçš„å†…å®¹
            cleaned_content = clean_generated_content(dify_result['content'])
            
            result = {
                'success': True,
                'message': f'Demoæµ‹è¯•æˆåŠŸ - çœŸå®Difyå·¥ä½œæµè°ƒç”¨',
                'data': {
                    'title': dify_result['title'],
                    'content': cleaned_content,
                    'images': dify_result['images'],
                    'video_info': {
                        'url': 'test_document.txt',
                        'language': language,
                        'picture_style': picture_style,
                        'duration': 'æµ‹è¯•æ–‡æ¡£'
                    },
                    'dify_raw': dify_result['dify_raw'],
                    'demo_info': {
                        'input_length': len(test_text),
                        'is_real_dify_call': True
                    }
                }
            }
            
            logging.info(f"DemoæˆåŠŸ - ç”Ÿæˆå†…å®¹é•¿åº¦: {len(cleaned_content)} å­—ç¬¦")
            return jsonify(result)
            
        except Exception as dify_error:
            logging.error(f"Difyè°ƒç”¨å¤±è´¥: {str(dify_error)}")
            
            # å¦‚æœDifyè°ƒç”¨å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
            result = {
                'success': False,
                'message': f'Demoæµ‹è¯•å¤±è´¥ - Difyå·¥ä½œæµè°ƒç”¨å‡ºé”™',
                'error': str(dify_error),
                'data': {
                    'title': 'Difyè°ƒç”¨å¤±è´¥',
                    'content': f'# Difyå·¥ä½œæµæµ‹è¯•å¤±è´¥\n\n**é”™è¯¯ä¿¡æ¯**: {str(dify_error)}\n\n**æµ‹è¯•æ–‡æ¡£**: {test_text[:200]}...',
                    'images': [],
                    'demo_info': {
                        'input_length': len(test_text),
                        'is_real_dify_call': True,
                        'error_occurred': True
                    }
                }
            }
            
            return jsonify(result), 500
        
    except Exception as e:
        logging.error(f"Demoå¤„ç†å¤±è´¥: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e),
            'message': 'Demoæ¥å£å¤„ç†å¤±è´¥'
        }), 500

if __name__ == '__main__':
    logger.info("ğŸ¬ å¯åŠ¨YouTubeè§†é¢‘è½¬å›¾æ–‡æ–‡ç« ç”Ÿæˆå™¨...")
    logger.info(f"ğŸ“ è®¿é—®åœ°å€: http://127.0.0.1:5015")
    
    app.run(
        host='127.0.0.1',
        port=5015,
        debug=True,
        threaded=True
    ) 